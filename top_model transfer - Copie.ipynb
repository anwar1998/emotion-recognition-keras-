{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5ebca254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import MobileNet\n",
    "from keras.models import Sequential,Model \n",
    "from keras.layers import Dense,Dropout,Activation,Flatten,GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D,MaxPooling2D,ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# MobileNet is designed to work with images of dim 224,224\n",
    "img_rows,img_cols = 224,224\n",
    "import pandas as ps\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import  pickle\n",
    "from keras.models import load_model\n",
    "from time import sleep\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2028b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model =load_model('data_utiliser/model-top.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4e1170b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 455       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 1,328,167\n",
      "Trainable params: 1,325,991\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5a3f4c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Activation at 0x26059fc05b0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "last_layer=top_model.get_layer('activation_21')\n",
    "last_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "242d1c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 7) dtype=float32 (created by layer 'activation_21')>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_output = last_layer.output\n",
    "last_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6c5770c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output=BatchNormalization()(last_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e842ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1fdd08be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 7) dtype=float32 (created by layer 'dens_8')>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output=layers.Dense(7,name=\"dens_8\")(final_output)\n",
    "\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "04092739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 7) dtype=float32 (created by layer 'activation_2')>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output=layers.Activation('relu')(final_output)\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ece5e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Model(inputs=top_model.input, outputs=final_output) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "90730d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8_input (InputLayer)  [(None, 48, 48, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 455       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7)                 28        \n",
      "_________________________________________________________________\n",
      "dens_8 (Dense)               (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 1,328,251\n",
      "Trainable params: 1,326,061\n",
      "Non-trainable params: 2,190\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c56836db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'C:/Users/Anouar Gmili/Desktop/images_fer2013/Training2'\n",
    "validation_data_dir = 'C:/Users/Anouar Gmili/Desktop/images_fer2013/validation'\n",
    "img_rows,img_cols = 48,48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "91d2af10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2861 images belonging to 7 classes.\n",
      "Found 412 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=30,\n",
    "                    width_shift_range=0.3,\n",
    "                    height_shift_range=0.3,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest'\n",
    "                                   )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                        train_data_dir,\n",
    "                        target_size = (img_rows,img_cols),\n",
    "                        batch_size = batch_size,\n",
    "    color_mode = \"grayscale\",\n",
    "                        class_mode = 'categorical'\n",
    "                        )\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                            validation_data_dir,\n",
    "                            target_size=(img_rows,img_cols),\n",
    "                            batch_size=batch_size,\n",
    "color_mode = \"grayscale\",\n",
    "                            class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "39d93408",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d202e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "                        'top_tap_tip3.h5',\n",
    "                             monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(\n",
    "                          monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=10,\n",
    "                          verbose=1,restore_best_weights=True)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=5,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.2,\n",
    "                                            min_lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "405a9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks = [earlystop,checkpoint,learning_rate_reduction]\n",
    "\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "\n",
    "nb_train_samples = 2861    \n",
    "nb_validation_samples = 412 \n",
    "epochs = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f18dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "89/89 [==============================] - 114s 1s/step - loss: 9.7526 - accuracy: 0.0881 - val_loss: 8.6309 - val_accuracy: 0.2552\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 8.63093, saving model to top_tap_tip3.h5\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 2/25\n",
      "89/89 [==============================] - 89s 995ms/step - loss: 8.6903 - accuracy: 0.1352 - val_loss: 7.6474 - val_accuracy: 0.0651\n",
      "\n",
      "Epoch 00002: val_loss improved from 8.63093 to 7.64745, saving model to top_tap_tip3.h5\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 3/25\n",
      "89/89 [==============================] - 87s 978ms/step - loss: 8.0354 - accuracy: 0.1702 - val_loss: 6.7564 - val_accuracy: 0.0781\n",
      "\n",
      "Epoch 00003: val_loss improved from 7.64745 to 6.75637, saving model to top_tap_tip3.h5\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 4/25\n",
      "89/89 [==============================] - 85s 953ms/step - loss: 7.7278 - accuracy: 0.1741 - val_loss: 7.0074 - val_accuracy: 0.0964\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 6.75637\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 5/25\n",
      "89/89 [==============================] - 89s 1s/step - loss: 7.3348 - accuracy: 0.1894 - val_loss: 8.8259 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 6.75637\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 6/25\n",
      "89/89 [==============================] - 83s 931ms/step - loss: 6.5397 - accuracy: 0.2104 - val_loss: 9.3375 - val_accuracy: 0.1172\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 6.75637\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 7/25\n",
      "89/89 [==============================] - 82s 924ms/step - loss: 6.2306 - accuracy: 0.2154 - val_loss: 8.8986 - val_accuracy: 0.0911\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 6.75637\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 8/25\n",
      "70/89 [======================>.......] - ETA: 17s - loss: 6.3115 - accuracy: 0.1874"
     ]
    }
   ],
   "source": [
    " history = new_model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=nb_train_samples//batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=nb_validation_samples//batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc655ec6",
   "metadata": {},
   "source": [
    "#### classifier =load_model('top_tap_tip .h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4a62366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.save(\"tata.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041c093d",
   "metadata": {},
   "source": [
    "# test de my model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "596da4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['Angry','Disgust','Fear','Happy','Neutral','Sad','Surprise']\n",
    "class_labels2 = ['Angry','Happy','Neutral','Sad','Surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2d7dda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade=cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "img_rows,img_cols = 224,224\n",
    "#MobileNet = MobileNet(weights='imagenet',include_top=False,input_shape=(img_rows,img_cols,3))\n",
    "recognizer =cv2.face.LBPHFaceRecognizer_create()\n",
    "labels2 ={\"personne_name\":1}\n",
    "face_classifier = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "010ce273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 48, 1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab a single frame of video\n",
    "\n",
    "frame=cv2.imread('sad_anouar.jpg')\n",
    "labels = []\n",
    "gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h,x:x+w]\n",
    "    roi_gray = cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n",
    "    plt.imshow(roi_gray)\n",
    "    if np.sum([roi_gray])!=0:\n",
    "        roi = roi_gray.astype('float')/255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi,axis=0)\n",
    "        #name = labels2[id_]\n",
    "roi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3c06dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=new_model.predict(roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e1d435e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63977885, 1.3803997 , 1.0351917 , 0.5192385 , 0.3111938 ,\n",
       "        0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4ba7765a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prediction max =  1\n",
      "\n",
      "label =  Disgust\n"
     ]
    }
   ],
   "source": [
    "label=class_labels[preds.argmax()]\n",
    "print(\"\\nprediction max = \",preds.argmax())\n",
    "print(\"\\nlabel = \",label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b5359",
   "metadata": {},
   "source": [
    "# deuxiemme chance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e34ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import MobileNet\n",
    "from keras.models import Sequential,Model \n",
    "from keras.layers import Dense,Dropout,Activation,Flatten,GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D,MaxPooling2D,ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# MobileNet is designed to work with images of dim 224,224\n",
    "img_rows,img_cols = 224,224\n",
    "import pandas as ps\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import  pickle\n",
    "from keras.models import load_model\n",
    "from time import sleep\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2d8cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model =load_model('data_utiliser/model-top.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c972d334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 455       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 1,328,167\n",
      "Trainable params: 1,325,991\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79413762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Activation at 0x23047238880>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "last_layer=top_model.get_layer('activation_21')\n",
    "last_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a34b2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTopModelMobileNet(bottom_model, num_classes):\n",
    "    \"\"\"creates the top or head of the model that will be\n",
    "    placed ontop of the bottom layers\"\"\"\n",
    "    top_model = bottom_model.output\n",
    "    #top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(7,activation='relu')(top_model)\n",
    "    top_model = Dense(7,activation='relu')(top_model)\n",
    "    top_model = Dense(7,activation='relu')(top_model)\n",
    "    top_model = Dense(num_classes,activation='softmax')(top_model)\n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2193eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8_input (InputLayer)  [(None, 48, 48, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 455       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 56        \n",
      "=================================================================\n",
      "Total params: 1,328,391\n",
      "Trainable params: 1,326,215\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_classes = 7\n",
    "\n",
    "FC_Head = addTopModelMobileNet(top_model, num_classes)\n",
    "\n",
    "model = Model(inputs = top_model.input, outputs = FC_Head)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ae558ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'C:/Users/Anouar Gmili/Desktop/images_fer2013/Training2'\n",
    "validation_data_dir = 'C:/Users/Anouar Gmili/Desktop/images_fer2013/validation'\n",
    "img_rows,img_cols = 48,48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee1beaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2861 images belonging to 7 classes.\n",
      "Found 412 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=30,\n",
    "                    width_shift_range=0.3,\n",
    "                    height_shift_range=0.3,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest'\n",
    "                                   )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                        train_data_dir,\n",
    "                        target_size = (img_rows,img_cols),\n",
    "                        batch_size = batch_size,\n",
    "    \n",
    "                        color_mode = \"grayscale\",\n",
    "\n",
    "                        class_mode = 'categorical'\n",
    "                        )\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                            validation_data_dir,\n",
    "                            target_size=(img_rows,img_cols),\n",
    "                            batch_size=batch_size,\n",
    "                            color_mode = \"grayscale\",\n",
    "\n",
    "                            class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dc9e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "472be653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "                        'top_tap_tiprelax.h5',\n",
    "                             monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(\n",
    "                          monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=10,\n",
    "                          verbose=1,restore_best_weights=True)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=5,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.2,\n",
    "                                            min_lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "108f5fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks = [earlystop,checkpoint,learning_rate_reduction]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "\n",
    "nb_train_samples = 2861    \n",
    "nb_validation_samples = 412 \n",
    "epochs = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c44b5766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "89/89 [==============================] - 87s 935ms/step - loss: 1.9038 - accuracy: 0.4275 - val_loss: 1.9816 - val_accuracy: 0.0859\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.98162, saving model to top_tap_tiprelax.h5\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 2/25\n",
      "89/89 [==============================] - 83s 935ms/step - loss: 1.7021 - accuracy: 0.4324 - val_loss: 2.1272 - val_accuracy: 0.0911\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.98162\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 3/25\n",
      "89/89 [==============================] - 94s 1s/step - loss: 1.6456 - accuracy: 0.4321 - val_loss: 2.1499 - val_accuracy: 0.0938\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.98162\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 4/25\n",
      "89/89 [==============================] - 95s 1s/step - loss: 1.6049 - accuracy: 0.4396 - val_loss: 2.1832 - val_accuracy: 0.0885\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.98162\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 5/25\n",
      "89/89 [==============================] - 89s 996ms/step - loss: 1.6147 - accuracy: 0.4265 - val_loss: 2.2140 - val_accuracy: 0.0938\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.98162\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 6/25\n",
      "89/89 [==============================] - 86s 969ms/step - loss: 1.6195 - accuracy: 0.4218 - val_loss: 2.1654 - val_accuracy: 0.0859\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.98162\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 7/25\n",
      "89/89 [==============================] - 94s 1s/step - loss: 1.5560 - accuracy: 0.4318 - val_loss: 2.0231 - val_accuracy: 0.2943\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.98162\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 8/25\n",
      "89/89 [==============================] - 86s 965ms/step - loss: 1.5375 - accuracy: 0.4711 - val_loss: 2.0407 - val_accuracy: 0.2891\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.98162\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 9/25\n",
      "89/89 [==============================] - 86s 963ms/step - loss: 1.5115 - accuracy: 0.4766 - val_loss: 2.0243 - val_accuracy: 0.2917\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.98162\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 10/25\n",
      "89/89 [==============================] - 95s 1s/step - loss: 1.4508 - accuracy: 0.4884 - val_loss: 1.8003 - val_accuracy: 0.3307\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.98162 to 1.80028, saving model to top_tap_tiprelax.h5\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 11/25\n",
      "89/89 [==============================] - 91s 1s/step - loss: 1.4494 - accuracy: 0.4660 - val_loss: 1.7731 - val_accuracy: 0.3307\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.80028 to 1.77314, saving model to top_tap_tiprelax.h5\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 12/25\n",
      "89/89 [==============================] - 84s 946ms/step - loss: 1.4093 - accuracy: 0.4957 - val_loss: 1.8244 - val_accuracy: 0.3151\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.77314\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 13/25\n",
      "89/89 [==============================] - 83s 931ms/step - loss: 1.3966 - accuracy: 0.5031 - val_loss: 1.6425 - val_accuracy: 0.3307\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.77314 to 1.64245, saving model to top_tap_tiprelax.h5\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 14/25\n",
      "89/89 [==============================] - 83s 934ms/step - loss: 1.3771 - accuracy: 0.4969 - val_loss: 1.6957 - val_accuracy: 0.3203\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.64245\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 15/25\n",
      "89/89 [==============================] - 85s 951ms/step - loss: 1.3909 - accuracy: 0.4714 - val_loss: 1.7250 - val_accuracy: 0.2865\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.64245\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 16/25\n",
      "89/89 [==============================] - 89s 999ms/step - loss: 1.3549 - accuracy: 0.4865 - val_loss: 1.6170 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.64245 to 1.61696, saving model to top_tap_tiprelax.h5\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 17/25\n",
      "89/89 [==============================] - 92s 1s/step - loss: 1.3411 - accuracy: 0.5056 - val_loss: 1.6511 - val_accuracy: 0.3359\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.61696\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 18/25\n",
      "89/89 [==============================] - 93s 1s/step - loss: 1.3320 - accuracy: 0.4975 - val_loss: 1.6293 - val_accuracy: 0.3516\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.61696\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 19/25\n",
      "89/89 [==============================] - 102s 1s/step - loss: 1.3098 - accuracy: 0.5197 - val_loss: 1.8764 - val_accuracy: 0.2995\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.61696\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 20/25\n",
      "89/89 [==============================] - 114s 1s/step - loss: 1.3168 - accuracy: 0.5193 - val_loss: 1.6936 - val_accuracy: 0.3307\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.61696\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 21/25\n",
      "89/89 [==============================] - 93s 1s/step - loss: 1.2970 - accuracy: 0.5373 - val_loss: 1.5618 - val_accuracy: 0.3698\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.61696 to 1.56177, saving model to top_tap_tiprelax.h5\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 22/25\n",
      "89/89 [==============================] - 100s 1s/step - loss: 1.2769 - accuracy: 0.5421 - val_loss: 1.5424 - val_accuracy: 0.3620\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.56177 to 1.54244, saving model to top_tap_tiprelax.h5\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 87s 972ms/step - loss: 1.2400 - accuracy: 0.5696 - val_loss: 1.5775 - val_accuracy: 0.3411\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.54244\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 24/25\n",
      "89/89 [==============================] - 84s 950ms/step - loss: 1.2289 - accuracy: 0.5555 - val_loss: 1.6712 - val_accuracy: 0.3776\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.54244\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 25/25\n",
      "89/89 [==============================] - 83s 937ms/step - loss: 1.2504 - accuracy: 0.5682 - val_loss: 1.6635 - val_accuracy: 0.3750\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.54244\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    }
   ],
   "source": [
    " history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=nb_train_samples//batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=nb_validation_samples//batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37690f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
